{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictionPart_Updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejyIaFYSjF7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data preprocessing\n",
        "import pandas as pd\n",
        "#produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\n",
        "import xgboost as xgb\n",
        "#the outcome (dependent variable) has only a limited number of possible values. \n",
        "#Logistic Regression is used when response variable is categorical in nature.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#A random forest is a meta estimator that fits a number of decision tree classifiers \n",
        "#on various sub-samples of the dataset and use averaging to improve the predictive \n",
        "#accuracy and control over-fitting.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#a discriminative classifier formally defined by a separating hyperplane.\n",
        "from sklearn.svm import SVC \n",
        "#displayd data\n",
        "from IPython.display import display\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxdPR2ANkCmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "DATA_PATH = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHWf-r0DjUIz",
        "colab_type": "code",
        "outputId": "0a656c1f-82a1-4662-9f7a-cf0d9e65ca2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sfDoWZKjoEt",
        "colab_type": "code",
        "outputId": "854702bf-7e0e-4acb-c041-06641d410643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOJV8rG3jpRi",
        "colab_type": "code",
        "outputId": "2201342f-ea97-4fab-f455-63a96386cb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = pd.read_csv(os.path.join(DATA_PATH, 'final_dataset.csv'))\n",
        "# Remove first 3 matchweeks\n",
        "data = data[data.MW > 3]\n",
        "#Drop all irrelevant statistics\n",
        "data.drop(['Unnamed: 0','HomeTeam', 'AwayTeam', 'Date', 'MW', 'HTFormPtsStr', 'ATFormPtsStr', 'FTHG', 'FTAG',\n",
        "           'HTGS', 'ATGS', 'HTGC', 'ATGC','HomeTeamLP', 'AwayTeamLP','DiffPts','HTFormPts','ATFormPts',\n",
        "           'HM4','HM5','AM4','AM5','HTLossStreak5','ATLossStreak5','HTWinStreak5','ATWinStreak5',\n",
        "           'HTWinStreak3','HTLossStreak3','ATWinStreak3','ATLossStreak3'],1, inplace=True)\n",
        "\n",
        "\n",
        "#Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "#HTGD - Home team goal difference\n",
        "#ATGD - away team goal difference\n",
        "#HTP - Home team points\n",
        "#ATP - Away team points\n",
        "#DiffFormPts Diff in points\n",
        "#DiffLP - Differnece in last years prediction\n",
        "\n",
        "#Input - 12 features\n",
        "#Output - Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "\n",
        "# Preview data.\n",
        "display(data.head())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FTR</th>\n",
              "      <th>HTP</th>\n",
              "      <th>ATP</th>\n",
              "      <th>HM1</th>\n",
              "      <th>HM2</th>\n",
              "      <th>HM3</th>\n",
              "      <th>AM1</th>\n",
              "      <th>AM2</th>\n",
              "      <th>AM3</th>\n",
              "      <th>HTGD</th>\n",
              "      <th>ATGD</th>\n",
              "      <th>DiffFormPts</th>\n",
              "      <th>DiffLP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>H</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>D</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>H</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>D</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>D</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>D</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.50</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>L</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FTR   HTP   ATP HM1 HM2 HM3 AM1 AM2 AM3  HTGD  ATGD  DiffFormPts  DiffLP\n",
              "30   H  1.25  1.00   D   D   W   D   W   L  0.50  0.25         0.25   -16.0\n",
              "31   D  0.75  0.25   L   L   W   D   L   L -0.50 -0.75         0.50    -2.0\n",
              "32   H  1.00  1.00   L   D   W   D   W   L  0.00  0.25         0.00    -3.0\n",
              "33   D  0.75  0.50   L   L   W   D   L   D -0.25 -0.25         0.25     3.0\n",
              "34   D  1.00  1.50   D   L   W   W   W   L  0.00  0.75        -0.50     3.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ad5p_BoYfV",
        "colab_type": "code",
        "outputId": "5762043d-4f86-41a8-a5db-2dff229ececb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Total number of matches.\n",
        "n_matches = data.shape[0]\n",
        "\n",
        "# Calculate number of features.\n",
        "n_features = data.shape[1] - 1\n",
        "\n",
        "# Calculate matches won by home team.\n",
        "n_homewins = len(data[data.FTR == 'H'])\n",
        "\n",
        "# Calculate win rate for home team.\n",
        "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
        "\n",
        "# Print the results\n",
        "print ('Total number of matches: {}'.format(n_matches))\n",
        "print ('Number of features: {}'.format(n_features))\n",
        "print ('Number of matches won by home team: {}'.format(n_homewins))\n",
        "print ('Win rate of home team: {:.2f}%'.format(win_rate))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 4900\n",
            "Number of features: 12\n",
            "Number of matches won by home team: 2289\n",
            "Win rate of home team: 46.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo4xem7Wpao5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pandas.tools.plotting import scatter_matrix\n",
        "# #this doesn't work because colab doesn't support this library\n",
        "# scatter_matrix(data[['HTGD','ATGD','HTP','ATP','DiffFormPts','DiffLP']], figsize=(10,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEINEDbjpoSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate into feature set and target variable\n",
        "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
        "X_all = data.drop(['FTR'],1)\n",
        "y_all = data['FTR']\n",
        "\n",
        "# Standardising the data.\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "cols = [['HTGD','ATGD','HTP','ATP','DiffLP']]\n",
        "for col in cols:\n",
        "    X_all[col] = scale(X_all[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEgFqBjLpya2",
        "colab_type": "code",
        "outputId": "d04533ae-48c1-4f3a-baf3-048412ebfbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_all.HM1 = X_all.HM1.astype('str')\n",
        "X_all.HM2 = X_all.HM2.astype('str')\n",
        "X_all.HM3 = X_all.HM3.astype('str')\n",
        "X_all.AM1 = X_all.AM1.astype('str')\n",
        "X_all.AM2 = X_all.AM2.astype('str')\n",
        "X_all.AM3 = X_all.AM3.astype('str')\n",
        "\n",
        "def preprocess_features(X):\n",
        "    ''' Preprocesses the football data and converts categorical variables into dummy variables. '''\n",
        "    \n",
        "    # Initialize new output DataFrame\n",
        "    output = pd.DataFrame(index = X.index)\n",
        "\n",
        "    # Investigate each feature column for the data\n",
        "    for col, col_data in X.iteritems():\n",
        "\n",
        "        # If data type is categorical, convert to dummy variables\n",
        "        if col_data.dtype == object:\n",
        "            col_data = pd.get_dummies(col_data, prefix = col)\n",
        "                    \n",
        "        # Collect the revised columns\n",
        "        output = output.join(col_data)\n",
        "    \n",
        "    return output\n",
        "\n",
        "X_all = preprocess_features(X_all)\n",
        "print ('Processed feature columns ({} total features):\\n{}'.format(len(X_all.columns), list(X_all.columns)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed feature columns (24 total features):\n",
            "['HTP', 'ATP', 'HM1_D', 'HM1_L', 'HM1_W', 'HM2_D', 'HM2_L', 'HM2_W', 'HM3_D', 'HM3_L', 'HM3_W', 'AM1_D', 'AM1_L', 'AM1_W', 'AM2_D', 'AM2_L', 'AM2_W', 'AM3_D', 'AM3_L', 'AM3_W', 'HTGD', 'ATGD', 'DiffFormPts', 'DiffLP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbBfiTdVqF5H",
        "colab_type": "code",
        "outputId": "3c5710b4-f6f0-4540-8c1c-661ba2a136ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Show the feature information by printing the first five rows\n",
        "print (\"\\nFeature values:\")\n",
        "display(X_all.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Feature values:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HTP</th>\n",
              "      <th>ATP</th>\n",
              "      <th>HM1_D</th>\n",
              "      <th>HM1_L</th>\n",
              "      <th>HM1_W</th>\n",
              "      <th>HM2_D</th>\n",
              "      <th>HM2_L</th>\n",
              "      <th>HM2_W</th>\n",
              "      <th>HM3_D</th>\n",
              "      <th>HM3_L</th>\n",
              "      <th>HM3_W</th>\n",
              "      <th>AM1_D</th>\n",
              "      <th>AM1_L</th>\n",
              "      <th>AM1_W</th>\n",
              "      <th>AM2_D</th>\n",
              "      <th>AM2_L</th>\n",
              "      <th>AM2_W</th>\n",
              "      <th>AM3_D</th>\n",
              "      <th>AM3_L</th>\n",
              "      <th>AM3_W</th>\n",
              "      <th>HTGD</th>\n",
              "      <th>ATGD</th>\n",
              "      <th>DiffFormPts</th>\n",
              "      <th>DiffLP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-0.046121</td>\n",
              "      <td>-0.617418</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.752387</td>\n",
              "      <td>0.356510</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-1.858670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-1.128800</td>\n",
              "      <td>-2.252347</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.733431</td>\n",
              "      <td>-1.133322</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.232147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.587460</td>\n",
              "      <td>-0.617418</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009478</td>\n",
              "      <td>0.356510</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.348327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-1.128800</td>\n",
              "      <td>-1.707371</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.361976</td>\n",
              "      <td>-0.388406</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.348754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-0.587460</td>\n",
              "      <td>0.472535</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009478</td>\n",
              "      <td>1.101426</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>0.348754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         HTP       ATP  HM1_D  HM1_L  ...      HTGD      ATGD  DiffFormPts    DiffLP\n",
              "30 -0.046121 -0.617418      1      0  ...  0.752387  0.356510         0.25 -1.858670\n",
              "31 -1.128800 -2.252347      0      1  ... -0.733431 -1.133322         0.50 -0.232147\n",
              "32 -0.587460 -0.617418      0      1  ...  0.009478  0.356510         0.00 -0.348327\n",
              "33 -1.128800 -1.707371      0      1  ... -0.361976 -0.388406         0.25  0.348754\n",
              "34 -0.587460  0.472535      1      0  ...  0.009478  1.101426        -0.50  0.348754\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZCxBFNLqRYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Shuffle and split the dataset into training and testing set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "                                                    test_size = 50,\n",
        "                                                    random_state = 2,\n",
        "                                                    stratify = y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gr5H3BKtuJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for measuring training time\n",
        "from time import time \n",
        "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
        "#It considers both the precision p and the recall r of the test to compute \n",
        "#the score: p is the number of correct positive results divided by the number of \n",
        "#all positive results, and r is the number of correct positive results divided by \n",
        "#the number of positive results that should have been returned. The F1 score can be \n",
        "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
        "#reaches its best value at 1 and worst at 0.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_classifier(clf, X_train, y_train):\n",
        "    ''' Fits a classifier to the training data. '''\n",
        "    \n",
        "    # Start the clock, train the classifier, then stop the clock\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    \n",
        "    # Print the results\n",
        "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
        "\n",
        "    \n",
        "def predict_labels(clf, features, target):\n",
        "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
        "    \n",
        "    # Start the clock, make predictions, then stop the clock\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    \n",
        "    end = time()\n",
        "    # Print and return results\n",
        "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
        "    \n",
        "    return f1_score(target, y_pred, pos_label='positive',average='weighted'), sum(target == y_pred) / float(len(y_pred))\n",
        "    # return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "    ''' Train and predict using a classifer based on F1 score. '''\n",
        "    \n",
        "    # Indicate the classifier and the training set size\n",
        "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
        "    \n",
        "    # Train the classifier\n",
        "    train_classifier(clf, X_train, y_train)\n",
        "    \n",
        "    # Print the results of prediction for both training and testing\n",
        "    f1, acc = predict_labels(clf, X_train, y_train)\n",
        "    print (f1, acc)\n",
        "    print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "    \n",
        "    f1, acc = predict_labels(clf, X_test, y_test)\n",
        "    print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbdtlUReuMx2",
        "colab_type": "code",
        "outputId": "d848db11-7437-40b3-cae2-893065c907af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# Initialize the three models (XGBoost is initialized later)\n",
        "clf_A = LogisticRegression(random_state = 42)\n",
        "clf_B = SVC(random_state = 912, kernel='rbf')\n",
        "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
        "#by combining rough and moderately inaccurate rules-of-thumb\n",
        "clf_C = xgb.XGBClassifier(seed = 82)\n",
        "\n",
        "train_predict(clf_A, X_train, y_train, X_test, y_test)\n",
        "print ('')\n",
        "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
        "print ('')\n",
        "train_predict(clf_C, X_train, y_train, X_test, y_test)\n",
        "print ('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training a LogisticRegression using a training set size of 4850. . .\n",
            "Trained model in 0.2269 seconds\n",
            "Made predictions in 0.0026 seconds.\n",
            "0.49686179219317383 0.5463917525773195\n",
            "F1 score and accuracy score for training set: 0.4969 , 0.5464.\n",
            "Made predictions in 0.0015 seconds.\n",
            "F1 score and accuracy score for test set: 0.4654 , 0.5200.\n",
            "\n",
            "Training a SVC using a training set size of 4850. . .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Trained model in 2.2530 seconds\n",
            "Made predictions in 1.1585 seconds.\n",
            "0.5335986937661085 0.5872164948453609\n",
            "F1 score and accuracy score for training set: 0.5336 , 0.5872.\n",
            "Made predictions in 0.0132 seconds.\n",
            "F1 score and accuracy score for test set: 0.4120 , 0.4800.\n",
            "\n",
            "Training a XGBClassifier using a training set size of 4850. . .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Trained model in 1.1723 seconds\n",
            "Made predictions in 0.0602 seconds.\n",
            "0.5477846117295458 0.5907216494845361\n",
            "F1 score and accuracy score for training set: 0.5478 , 0.5907.\n",
            "Made predictions in 0.0021 seconds.\n",
            "F1 score and accuracy score for test set: 0.4602 , 0.5200.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUO5Wdi1jM8P",
        "colab_type": "text"
      },
      "source": [
        "**Clearly XGBoost seems like the best model as it has the highest F1 score and accuracy score on the test set.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdWxC4tSupR7",
        "colab_type": "code",
        "outputId": "cdfe8e9b-49f8-453b-9cc9-2d260edad3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Import 'GridSearchCV' and 'make_scorer'\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "\n",
        "# Create the parameters list you wish to tune\n",
        "parameters = { 'learning_rate' : [0.1],\n",
        "               'n_estimators' : [40],\n",
        "               'max_depth': [3],\n",
        "               'min_child_weight': [3],\n",
        "               'gamma':[0.4],\n",
        "               'subsample' : [0.8],\n",
        "               'colsample_bytree' : [0.8],\n",
        "               'scale_pos_weight' : [1],\n",
        "               'reg_alpha':[1e-5]\n",
        "             }  \n",
        "\n",
        "# Initialize the classifier\n",
        "clf = xgb.XGBClassifier(seed=2)\n",
        "\n",
        "# Make an f1 scoring function using 'make_scorer' \n",
        "f1_scorer = make_scorer(f1_score,pos_label='positive',average='weighted')\n",
        "# f1_scorer = make_scorer(f1_score,pos_label='H')\n",
        "\n",
        "\n",
        "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "grid_obj = GridSearchCV(clf,\n",
        "                        scoring=f1_scorer,\n",
        "                        param_grid=parameters,\n",
        "                        cv=5)\n",
        "\n",
        "# Fit the grid search object to the training data and find the optimal parameters\n",
        "grid_obj = grid_obj.fit(X_train,y_train)\n",
        "\n",
        "# Get the estimator\n",
        "clf = grid_obj.best_estimator_\n",
        "print (clf)\n",
        "\n",
        "# Report the final F1 score for training and testing after parameter tuning\n",
        "f1, acc = predict_labels(clf, X_train, y_train)\n",
        "print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "    \n",
        "f1, acc = predict_labels(clf, X_test, y_test)\n",
        "print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=3, missing=None, n_estimators=40, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, seed=2,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "Made predictions in 0.0250 seconds.\n",
            "F1 score and accuracy score for training set: 0.5192 , 0.5722.\n",
            "Made predictions in 0.0015 seconds.\n",
            "F1 score and accuracy score for test set: 0.4602 , 0.5200.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA6Z-iA74M1z",
        "colab_type": "code",
        "outputId": "8ac20970-665a-43e0-bdbf-c20b1274d948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Import 'GridSearchCV' and 'make_scorer'\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Create the parameters list you wish to tune\n",
        "parameters = { 'learning_rate' : [0.03],\n",
        "               'n_estimators' : [20],\n",
        "               'max_depth': [5],\n",
        "               'min_child_weight': [5],\n",
        "               'gamma':[0.2],\n",
        "               'subsample':[0.8],\n",
        "               'colsample_bytree':[0.8],\n",
        "               'scale_pos_weight' : [1],\n",
        "               'reg_alpha':[1e-2]\n",
        "             }  \n",
        "\n",
        "# Initialize the classifier\n",
        "clf = xgb.XGBClassifier(seed=2)\n",
        "\n",
        "# Make an f1 scoring function using 'make_scorer' \n",
        "f1_scorer = make_scorer(f1_score,pos_label='positive', average='weighted')\n",
        "# f1_scorer = make_scorer(f1_score,pos_label='H')\n",
        "\n",
        "\n",
        "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "grid_obj = GridSearchCV(clf,\n",
        "                        scoring=f1_scorer,\n",
        "                        param_grid=parameters,\n",
        "                        cv=5)\n",
        "\n",
        "# Fit the grid search object to the training data and find the optimal parameters\n",
        "grid_obj = grid_obj.fit(X_all,y_all)\n",
        "\n",
        "# Get the estimator\n",
        "clf = grid_obj.best_estimator_\n",
        "print (clf)\n",
        "\n",
        "# Report the final F1 score for training and testing after parameter tuning\n",
        "f1, acc = predict_labels(clf, X_train, y_train)\n",
        "print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.2,\n",
            "              learning_rate=0.03, max_delta_step=0, max_depth=5,\n",
            "              min_child_weight=5, missing=None, n_estimators=20, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=0,\n",
            "              reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=2,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "Made predictions in 0.0213 seconds.\n",
            "F1 score and accuracy score for training set: 0.5470 , 0.5955.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPLC-B53G_hD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF9x6_aVIus-",
        "colab_type": "code",
        "outputId": "bd61ec8e-3349-4681-bad7-660e3ac541b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# X_test\n",
        "test_labels = clf.predict(X_test[:])\n",
        "print(test_labels)\n",
        "# print(X_test[0][2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['H' 'H' 'A' 'A' 'H' 'A' 'H' 'H' 'A' 'H' 'A' 'H' 'A' 'H' 'D' 'H' 'H' 'H'\n",
            " 'H' 'H' 'H' 'A' 'H' 'A' 'H' 'H' 'H' 'H' 'H' 'H' 'A' 'H' 'H' 'H' 'H' 'H'\n",
            " 'H' 'D' 'A' 'A' 'H' 'A' 'H' 'H' 'D' 'H' 'H' 'H' 'H' 'H']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm9PNGntRr0D",
        "colab_type": "code",
        "outputId": "3f88e987-2b39-47f6-b5ea-65f2628c7a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "true_labels = y_test.to_numpy()\n",
        "print(true_labels[:])\n",
        "print(type(true_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A' 'D' 'H' 'A' 'H' 'A' 'H' 'H' 'A' 'H' 'H' 'D' 'H' 'D' 'A' 'D' 'A' 'H'\n",
            " 'H' 'A' 'H' 'A' 'D' 'A' 'D' 'H' 'H' 'A' 'D' 'H' 'D' 'H' 'H' 'H' 'H' 'H'\n",
            " 'H' 'D' 'A' 'A' 'H' 'H' 'D' 'D' 'D' 'H' 'A' 'D' 'A' 'H']\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3bNONO0yo0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare(test_labels, true_labels):\n",
        "  coincidencelist = []\n",
        "  for i in range(len(test_labels)):\n",
        "    if test_labels[i] == true_labels[i]:\n",
        "      coincidencelist.append(test_labels[i])\n",
        "\n",
        "  accuracy = len(coincidencelist)*100/len(test_labels)\n",
        "  return len(coincidencelist), len(test_labels), accuracy \n",
        "    # for j in range(len(true_labels)):\n",
        "    #   if true_labels[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1j5ZtZBGnLT",
        "colab_type": "code",
        "outputId": "5e459802-3343-4e2d-92d7-8d29da2b0af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compare(test_labels, true_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 50, 56.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxWhKaUT4gg3",
        "colab_type": "text"
      },
      "source": [
        "**FINISHED**"
      ]
    }
  ]
}